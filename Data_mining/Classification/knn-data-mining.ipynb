{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sean Pharris\n# Model: K Nearest Neighbor\n# Data set: Customer data of a telecommunications company\n# Date: Jan 21, 2022","metadata":{}},{"cell_type":"markdown","source":"## Part I: Research Question\n\nA.\n\n1.  What customers are likely to discontinue their services in the next few months?\n\n2.  The goal of identifying the results to our research question can help the stakeholders to understand the turn over of customers in detail.\n \n\n## Part II: Method Justification\n\nB.  \n\n1.  The K Nearest Neighbor algorithim will classify our data case by case to determine whether each data point will be a point indicating customer churn or not. That method includes:\n    * Classifying all points\n    * Determining what K will be (K is the number of surrounding points to classify the point at focus)\n    * Generalizing the overall outcome with the number of total points\n    \n    Outcome: What customers will be at risk of customer churn\n\n2.  Assumptions:\n* KNN assumes that the data is in a feature space. More exactly, the data points are in a metric space. The data can be scalars or possibly even multidimensional vectors. Since the points are in feature space, they have a notion of distance – This need not necessarily be Euclidean distance although it is the one commonly used (Thirumuruganathan, S. (2010)).\n\n* Each of the training data consists of a set of vectors and class label associated with each vector. In the simplest case , it will be either + or – (for positive or negative classes). But KNN , can work equally well with arbitrary number of classes (Thirumuruganathan, S. (2010)).\n\n* We are also given a single number \"k\" . This number decides how many neighbors (where neighbors is defined based on the distance metric) influence the classification. This is usually a odd number if the number of classes is 2. If k=1 , then the algorithm is simply called the nearest neighbor algorithm (Thirumuruganathan, S. (2010)).\n\n3.  The benefits of Python are vast but the main reason are the versatility, ease of use, and strong support from the community. There are many packages that make it easy to undertake the task of doing data analysis/data prediction.\n\n* Some of those packages are:\n    * Pandas and Numpy - make it easy to handle large sets of data\n    * Seaborn and Matplotlib - make data visualization a breeze\n    * Statsmodels and ScikitLearn - allow for easy data exploration and prediction\n \n\n## Part III: Data Preparation\n\nC.  \n\n1.  The customers that have already discontinued their services in the last month have the binary variable as \"yes\" in the \"Churn\" column and \"no\" for those customers that have no discontinued their services. We will preprocess the data as 1s for \"yes\" and 0s for \"no\" to process the data. \n\n2.  The initial data set will include the variables below and our dependent variable will be \"Churn\", which is categorical.\n\n* Continuous:\n\n    'Population', 'Children', 'Age', 'Income', 'Outage_sec_perweek', 'Email', 'Contacts', 'Yearly_equip_failure', 'Tenure', 'MonthlyCharge', 'Bandwidth_GB_Year', 'TimelyResponse', 'TimelyFixes', 'TimelyReplacements', 'Reliability', 'Options', 'RespectfulResponse', 'CourteousExchange', 'EvidenceOfActiveListening'\n       \n* Categorical: \n\n    'Area', 'TimeZone', 'Job', 'Marital', 'Gender', 'Techie', 'Contract', 'Port_modem', 'Tablet', 'InternetService', 'Phone', 'Multiple', 'OnlineSecurity','OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'PaymentMethod'\n\n\n3.  Steps to prepare data:\n    1. Read the data into the data frame (\"df\") using Pandas \"read_csv()\"\n    2. Drop unneeded columns\n    3. Changing the names of columns to make the data more understandable\n    4. Make sure there are no null values\n    5. Create dummy variables for categorical columns\n    6. Remove the outliers of numerical data types","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-25T11:42:57.777781Z","iopub.execute_input":"2022-01-25T11:42:57.778315Z","iopub.status.idle":"2022-01-25T11:42:57.814182Z","shell.execute_reply.started":"2022-01-25T11:42:57.778211Z","shell.execute_reply":"2022-01-25T11:42:57.813306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:57.8162Z","iopub.execute_input":"2022-01-25T11:42:57.816538Z","iopub.status.idle":"2022-01-25T11:42:57.820643Z","shell.execute_reply.started":"2022-01-25T11:42:57.816492Z","shell.execute_reply":"2022-01-25T11:42:57.819827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import the data","metadata":{}},{"cell_type":"code","source":"# Read in data set into the data frame \ndf = pd.read_csv('../input/clean-churn-data/churn_clean.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:57.821871Z","iopub.execute_input":"2022-01-25T11:42:57.822102Z","iopub.status.idle":"2022-01-25T11:42:58.002764Z","shell.execute_reply.started":"2022-01-25T11:42:57.822074Z","shell.execute_reply":"2022-01-25T11:42:58.001823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing unneeded columns","metadata":{}},{"cell_type":"code","source":"# Drop unnecessary columns\ndf.drop(columns=['CaseOrder','UID', 'Customer_id','Interaction', 'Job','State','City','County','Zip','Lat','Lng', 'TimeZone', 'Marital'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.00462Z","iopub.execute_input":"2022-01-25T11:42:58.004849Z","iopub.status.idle":"2022-01-25T11:42:58.025718Z","shell.execute_reply.started":"2022-01-25T11:42:58.004821Z","shell.execute_reply":"2022-01-25T11:42:58.025064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.026771Z","iopub.execute_input":"2022-01-25T11:42:58.027045Z","iopub.status.idle":"2022-01-25T11:42:58.064649Z","shell.execute_reply.started":"2022-01-25T11:42:58.027013Z","shell.execute_reply":"2022-01-25T11:42:58.063823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Changing the name of columns to make the data more understandable","metadata":{}},{"cell_type":"code","source":"# Renaming the survey columns\ndf.rename(columns = {'Item1':'TimelyResponse', \n                    'Item2':'TimelyFixes', \n                     'Item3':'TimelyReplacements', \n                     'Item4':'Reliability', \n                     'Item5':'Options', \n                     'Item6':'RespectfulResponse', \n                     'Item7':'CourteousExchange', \n                     'Item8':'EvidenceOfActiveListening'}, \n          inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.066099Z","iopub.execute_input":"2022-01-25T11:42:58.066345Z","iopub.status.idle":"2022-01-25T11:42:58.072012Z","shell.execute_reply.started":"2022-01-25T11:42:58.066317Z","shell.execute_reply":"2022-01-25T11:42:58.071192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.073301Z","iopub.execute_input":"2022-01-25T11:42:58.073785Z","iopub.status.idle":"2022-01-25T11:42:58.086472Z","shell.execute_reply.started":"2022-01-25T11:42:58.07374Z","shell.execute_reply":"2022-01-25T11:42:58.085331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for null values in the data set","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.08825Z","iopub.execute_input":"2022-01-25T11:42:58.089071Z","iopub.status.idle":"2022-01-25T11:42:58.12547Z","shell.execute_reply.started":"2022-01-25T11:42:58.088986Z","shell.execute_reply":"2022-01-25T11:42:58.124611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Below, we will find our categorical data types","metadata":{}},{"cell_type":"code","source":"# find categorical variables\n\ncategorical = [var for var in df.columns if df[var].dtype=='O']\n\nprint('There are {} categorical variables\\n'.format(len(categorical)))\n\nprint('The categorical variables are :', categorical)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.127712Z","iopub.execute_input":"2022-01-25T11:42:58.128298Z","iopub.status.idle":"2022-01-25T11:42:58.140656Z","shell.execute_reply.started":"2022-01-25T11:42:58.128252Z","shell.execute_reply":"2022-01-25T11:42:58.139824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view the categorical variables\n\nprint(categorical)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.144585Z","iopub.execute_input":"2022-01-25T11:42:58.146322Z","iopub.status.idle":"2022-01-25T11:42:58.151472Z","shell.execute_reply.started":"2022-01-25T11:42:58.146265Z","shell.execute_reply":"2022-01-25T11:42:58.150755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for cardinality in categorical variables\n\nfor var in df:\n    print(var, ' contains ', len(df[var].unique()), ' labels')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.152898Z","iopub.execute_input":"2022-01-25T11:42:58.153456Z","iopub.status.idle":"2022-01-25T11:42:58.212162Z","shell.execute_reply.started":"2022-01-25T11:42:58.153413Z","shell.execute_reply":"2022-01-25T11:42:58.211305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Below we will find out numerical data types and remove outliers","metadata":{}},{"cell_type":"code","source":"# find numerical variables\n\nnumerical = [var for var in df.columns if df[var].dtype!='O']\n\nprint('There are {} numerical variables\\n'.format(len(numerical)))\n\nprint('The numerical variables are :', numerical)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.213864Z","iopub.execute_input":"2022-01-25T11:42:58.214182Z","iopub.status.idle":"2022-01-25T11:42:58.220841Z","shell.execute_reply.started":"2022-01-25T11:42:58.214137Z","shell.execute_reply":"2022-01-25T11:42:58.220035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now we will look for outliers","metadata":{}},{"cell_type":"code","source":"# view summary statistics in numerical variables\n\nprint(round(df.describe()),2)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.222392Z","iopub.execute_input":"2022-01-25T11:42:58.222688Z","iopub.status.idle":"2022-01-25T11:42:58.313058Z","shell.execute_reply.started":"2022-01-25T11:42:58.222648Z","shell.execute_reply":"2022-01-25T11:42:58.312214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Variables that may contain outliers:\n\n* Population\n* Income\n* Bandwidth_GB_Year","metadata":{}},{"cell_type":"code","source":"# draw boxplots to visualize outliers\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(15,10))\n\n\nplt.subplot(2, 2, 1)\nfig = df.boxplot(column='Population')\nfig.set_title('')\nfig.set_ylabel('Population')\n\n\nplt.subplot(2, 2, 2)\nfig = df.boxplot(column='Income')\nfig.set_title('')\nfig.set_ylabel('Income')\n\n\nplt.subplot(2, 2, 3)\nfig = df.boxplot(column='Bandwidth_GB_Year')\nfig.set_title('')\nfig.set_ylabel('Bandwidth_GB_Year')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.314615Z","iopub.execute_input":"2022-01-25T11:42:58.314905Z","iopub.status.idle":"2022-01-25T11:42:58.980973Z","shell.execute_reply.started":"2022-01-25T11:42:58.314866Z","shell.execute_reply":"2022-01-25T11:42:58.980069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot histogram to check distribution\n\nplt.figure(figsize=(15,10))\n\n\nplt.subplot(2, 2, 1)\nfig = df.Population.hist(bins=10)\nfig.set_xlabel('Population')\nfig.set_ylabel('Churn')\n\n\nplt.subplot(2, 2, 2)\nfig = df.Income.hist(bins=10)\nfig.set_xlabel('Income')\nfig.set_ylabel('Churn')\n\n\nplt.subplot(2, 2, 3)\nfig = df.Bandwidth_GB_Year.hist(bins=10)\nfig.set_xlabel('Bandwidth_GB_Year')\nfig.set_ylabel('Churn')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:58.982598Z","iopub.execute_input":"2022-01-25T11:42:58.982916Z","iopub.status.idle":"2022-01-25T11:42:59.597846Z","shell.execute_reply.started":"2022-01-25T11:42:58.982873Z","shell.execute_reply":"2022-01-25T11:42:59.596834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing the outliers in our numerical data types\n* Bandwidth_GB_Year does not appear to be skewed.\n* Population and income apprear to be skewed so we will conduct an interquantile range now.","metadata":{}},{"cell_type":"code","source":"# find outliers for Population\n\nIQR = df.Population.quantile(0.75) - df.Population.quantile(0.25)\nlower = df.Population.quantile(0.25) - (IQR * 3)\nupper = df.Population.quantile(0.75) + (IQR * 3)\nprint('Population outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=lower, upperboundary=upper))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:59.599591Z","iopub.execute_input":"2022-01-25T11:42:59.599921Z","iopub.status.idle":"2022-01-25T11:42:59.614797Z","shell.execute_reply.started":"2022-01-25T11:42:59.599879Z","shell.execute_reply":"2022-01-25T11:42:59.613914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find outliers for Income\n\nIQR = df.Income.quantile(0.75) - df.Income.quantile(0.25)\nlower = df.Income.quantile(0.25) - (IQR * 3)\nupper = df.Income.quantile(0.75) + (IQR * 3)\nprint('Income outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=lower, upperboundary=upper))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:59.615966Z","iopub.execute_input":"2022-01-25T11:42:59.616292Z","iopub.status.idle":"2022-01-25T11:42:59.632971Z","shell.execute_reply.started":"2022-01-25T11:42:59.616259Z","shell.execute_reply":"2022-01-25T11:42:59.631967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fixing the outliers in our numerical data types\n\n* We have seen that the Population and Income columns contain outliers. \n* We will use top-coding approach to cap maximum values and remove outliers from the above variables.","metadata":{}},{"cell_type":"code","source":"def max_value(df3, variable, top):\n    return np.where(df3[variable]>top, top, df3[variable])\n\nfor df3 in [df]:\n    df3['Population'] = max_value(df3, 'Population', 50458.0)\n    df3['Income'] = max_value(df3, 'Income', 155310.5275)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:59.634809Z","iopub.execute_input":"2022-01-25T11:42:59.635626Z","iopub.status.idle":"2022-01-25T11:42:59.644277Z","shell.execute_reply.started":"2022-01-25T11:42:59.635568Z","shell.execute_reply":"2022-01-25T11:42:59.643383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.Population.max(), df.Income.max())","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:59.646157Z","iopub.execute_input":"2022-01-25T11:42:59.646489Z","iopub.status.idle":"2022-01-25T11:42:59.659667Z","shell.execute_reply.started":"2022-01-25T11:42:59.646446Z","shell.execute_reply":"2022-01-25T11:42:59.659017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot histogram to check distribution of removed outliers \n\nplt.figure(figsize=(15,10))\n\n\nplt.subplot(2, 2, 1)\nfig = df.Population.hist(bins=10)\nfig.set_xlabel('Population')\nfig.set_ylabel('Churn')\n\n\nplt.subplot(2, 2, 2)\nfig = df.Income.hist(bins=10)\nfig.set_xlabel('Income')\nfig.set_ylabel('Churn')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:42:59.660622Z","iopub.execute_input":"2022-01-25T11:42:59.661462Z","iopub.status.idle":"2022-01-25T11:43:00.102064Z","shell.execute_reply.started":"2022-01-25T11:42:59.661425Z","shell.execute_reply":"2022-01-25T11:43:00.101207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### C4.  Provide a copy of the cleaned data set.","metadata":{}},{"cell_type":"code","source":"# Desired data set\ndf.to_csv('KNN_churn.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:00.103591Z","iopub.execute_input":"2022-01-25T11:43:00.104062Z","iopub.status.idle":"2022-01-25T11:43:00.295912Z","shell.execute_reply.started":"2022-01-25T11:43:00.104018Z","shell.execute_reply":"2022-01-25T11:43:00.295087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### D1.  Split the data into training and test data sets and provide the file(s).","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Create arrays for the features and the response variable\n\ntrain, test = train_test_split(df, test_size = 0.2, random_state = 0)\n\n# check the shape of X_train and X_test\n\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:00.297569Z","iopub.execute_input":"2022-01-25T11:43:00.297877Z","iopub.status.idle":"2022-01-25T11:43:01.180056Z","shell.execute_reply.started":"2022-01-25T11:43:00.297835Z","shell.execute_reply":"2022-01-25T11:43:01.179138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put training and test data into their own CSVs.\n\ntrain.to_csv('training_churn.csv', index=False)\n\ntest.to_csv('test_churn.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:01.182056Z","iopub.execute_input":"2022-01-25T11:43:01.18231Z","iopub.status.idle":"2022-01-25T11:43:01.377269Z","shell.execute_reply.started":"2022-01-25T11:43:01.182281Z","shell.execute_reply":"2022-01-25T11:43:01.376347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now that we have split the test/training data, we will split the dependent variable \"Churn\" from the independent variables.","metadata":{}},{"cell_type":"code","source":"# create target(predictor) variable \n\nX = df.drop(['Churn'], axis=1)\n\ny = df['Churn']","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:01.37975Z","iopub.execute_input":"2022-01-25T11:43:01.380034Z","iopub.status.idle":"2022-01-25T11:43:01.388621Z","shell.execute_reply.started":"2022-01-25T11:43:01.380003Z","shell.execute_reply":"2022-01-25T11:43:01.387585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# removing churn from categorical list because we will loop through the categorical in the encoding below\n\ncategorical.remove('Churn')\n\ncategorical","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:01.390219Z","iopub.execute_input":"2022-01-25T11:43:01.390605Z","iopub.status.idle":"2022-01-25T11:43:01.401717Z","shell.execute_reply.started":"2022-01-25T11:43:01.390447Z","shell.execute_reply":"2022-01-25T11:43:01.401108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nfor feature in categorical:\n    X.loc[:, feature] = le.fit_transform(X.loc[:, feature])","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:01.402794Z","iopub.execute_input":"2022-01-25T11:43:01.403552Z","iopub.status.idle":"2022-01-25T11:43:01.484798Z","shell.execute_reply.started":"2022-01-25T11:43:01.403517Z","shell.execute_reply":"2022-01-25T11:43:01.484012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalizaing/feature scaling the data\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:01.485851Z","iopub.execute_input":"2022-01-25T11:43:01.486063Z","iopub.status.idle":"2022-01-25T11:43:01.510755Z","shell.execute_reply.started":"2022-01-25T11:43:01.486037Z","shell.execute_reply":"2022-01-25T11:43:01.509948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split X and y into training and testing sets\n\nfrom sklearn.model_selection import cross_val_score, train_test_split\n\n# Set seed for reproducibility\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# check the shape of X_train and X_test\n\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:01.514742Z","iopub.execute_input":"2022-01-25T11:43:01.515531Z","iopub.status.idle":"2022-01-25T11:43:01.528603Z","shell.execute_reply.started":"2022-01-25T11:43:01.515477Z","shell.execute_reply":"2022-01-25T11:43:01.527829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part IV: Analysis\n\n### D2.  Analysis and intermediate calculations","metadata":{"execution":{"iopub.status.busy":"2022-01-21T13:07:59.72Z","iopub.execute_input":"2022-01-21T13:07:59.720383Z","iopub.status.idle":"2022-01-21T13:07:59.727422Z","shell.execute_reply.started":"2022-01-21T13:07:59.720339Z","shell.execute_reply":"2022-01-21T13:07:59.725986Z"}}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\n\nn_neighbors = 3\nrandom_state = 0\n\n# Create a k-NN classifier with 3 neighbors\nknn = KNeighborsClassifier(n_neighbors=3)\n\n# Fit the method's model\nknn.fit(X_train, y_train)\n\n# predict the results and get accuracy of the model\ny_pred = knn.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:01.529674Z","iopub.execute_input":"2022-01-25T11:43:01.529905Z","iopub.status.idle":"2022-01-25T11:43:03.219797Z","shell.execute_reply.started":"2022-01-25T11:43:01.529873Z","shell.execute_reply":"2022-01-25T11:43:03.218873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### D3.  Code is above.\n \n\n## Part V: Data Summary and Implications\n\n### E1.  Accuracy and AUC","metadata":{}},{"cell_type":"code","source":"measure = le.fit_transform(y_pred)\nmeasure_test = le.fit_transform(y_test)\nmeasure_test","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:03.221205Z","iopub.execute_input":"2022-01-25T11:43:03.221467Z","iopub.status.idle":"2022-01-25T11:43:03.229965Z","shell.execute_reply.started":"2022-01-25T11:43:03.221435Z","shell.execute_reply":"2022-01-25T11:43:03.229031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nmse = mean_squared_error(measure_test, measure)\n\n\nmodel_acc = 'Model accuracy: {0:0.4f}'. format(accuracy_score(y_test, y_pred))\nprint(model_acc)\nmse_acc = 'MSE accuracy: {0:0.4f}'. format(mse)\nprint(mse_acc)\nr_squared = 'R-squared value:', knn.score(X_test,y_test)\nprint(r_squared)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:03.231367Z","iopub.execute_input":"2022-01-25T11:43:03.231664Z","iopub.status.idle":"2022-01-25T11:43:04.727907Z","shell.execute_reply.started":"2022-01-25T11:43:03.231624Z","shell.execute_reply":"2022-01-25T11:43:04.727074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ninitial_model_report = classification_report(y_test, y_pred)\n# classification metrics\nprint(initial_model_report)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:04.729156Z","iopub.execute_input":"2022-01-25T11:43:04.729364Z","iopub.status.idle":"2022-01-25T11:43:04.833405Z","shell.execute_reply.started":"2022-01-25T11:43:04.729338Z","shell.execute_reply":"2022-01-25T11:43:04.832778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import sklearn confusion_matrix & generate results\n\nfrom sklearn.metrics import confusion_matrix\n\ncfm = confusion_matrix(y_test, y_pred)\nprint(cfm)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:04.834238Z","iopub.execute_input":"2022-01-25T11:43:04.834439Z","iopub.status.idle":"2022-01-25T11:43:04.853786Z","shell.execute_reply.started":"2022-01-25T11:43:04.834413Z","shell.execute_reply":"2022-01-25T11:43:04.852936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\n# chart confusion matrix\ncategories = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n\ncat_amount = [\"{0:0.0f}\".format(value) for value in cfm.flatten()]\n\ncat_percent = [\"{0:.2%}\".format(value) for value in cfm.flatten()/np.sum(cfm)]\n\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(categories,cat_amount,cat_percent)]\n\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap(cfm, annot=labels, fmt='', cmap='Greens')","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:04.855512Z","iopub.execute_input":"2022-01-25T11:43:04.855825Z","iopub.status.idle":"2022-01-25T11:43:05.384072Z","shell.execute_reply.started":"2022-01-25T11:43:04.855781Z","shell.execute_reply":"2022-01-25T11:43:05.383239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nauc_est = (roc_auc_score(measure_test, measure))\n\nprint(\"The AUC on validation dataset is\", auc_est)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:45:59.139715Z","iopub.execute_input":"2022-01-25T11:45:59.140024Z","iopub.status.idle":"2022-01-25T11:45:59.149994Z","shell.execute_reply.started":"2022-01-25T11:45:59.13999Z","shell.execute_reply":"2022-01-25T11:45:59.148886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\n\nfpr, tpr, thresholds = metrics.roc_curve(measure_test, measure)\nroc_auc = metrics.auc(fpr, tpr)\ndisplay = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n                                  estimator_name='AUC Estimate')\ndisplay.plot()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:57:00.185619Z","iopub.execute_input":"2022-01-25T11:57:00.185931Z","iopub.status.idle":"2022-01-25T11:57:00.389259Z","shell.execute_reply.started":"2022-01-25T11:57:00.185888Z","shell.execute_reply":"2022-01-25T11:57:00.388197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy and AUC Conclusion:\n    * The accuracy of the model is a .8\n    * The precision is .8 as well\n    * The area under the curve is approximately .6.\n        * When 0.5<AUC<1, there is a high chance that the classifier will be able to distinguish the positive class values from the negative class values (Bhandari, A. (2020)). ","metadata":{}},{"cell_type":"markdown","source":"### Now going to attempt improve accuracy and reduce the dimensions of the model for efficiency","metadata":{}},{"cell_type":"code","source":"to_be_reduced_X = X_test\nto_be_reduced_y = y_test","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:05.385603Z","iopub.execute_input":"2022-01-25T11:43:05.385996Z","iopub.status.idle":"2022-01-25T11:43:05.390064Z","shell.execute_reply.started":"2022-01-25T11:43:05.385951Z","shell.execute_reply":"2022-01-25T11:43:05.389387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.inspection import permutation_importance\nfrom sklearn.datasets import make_classification\n\nto_be_reduced_X, to_be_reduced_y = make_classification(n_samples=len(to_be_reduced_X), n_features=len(to_be_reduced_X.columns), random_state=1)\n\n# define the model\nmodel = KNeighborsClassifier()\n\n# fit the model\nmodel.fit(to_be_reduced_X, to_be_reduced_y)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:05.391017Z","iopub.execute_input":"2022-01-25T11:43:05.391744Z","iopub.status.idle":"2022-01-25T11:43:05.582729Z","shell.execute_reply.started":"2022-01-25T11:43:05.391695Z","shell.execute_reply":"2022-01-25T11:43:05.581872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find the feature importance\n\nresults = permutation_importance(model, to_be_reduced_X, to_be_reduced_y, scoring='accuracy')\n\nimportance = results.importances_mean","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:43:05.584187Z","iopub.execute_input":"2022-01-25T11:43:05.585091Z","iopub.status.idle":"2022-01-25T11:44:16.612321Z","shell.execute_reply.started":"2022-01-25T11:43:05.585042Z","shell.execute_reply":"2022-01-25T11:44:16.61138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize feature importance\n\nfor i,v in enumerate(importance):\n    print(X_test.columns[i], ': %0d, Score: %.5f' % (i,v))\n    \n# plot feature importance\nplt.figure(figsize=(10, 10))\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:44:16.613644Z","iopub.execute_input":"2022-01-25T11:44:16.613902Z","iopub.status.idle":"2022-01-25T11:44:16.905121Z","shell.execute_reply.started":"2022-01-25T11:44:16.613862Z","shell.execute_reply":"2022-01-25T11:44:16.90429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats = []\nfor i,v in enumerate(importance):\n    if v > 0.003:\n        feats.append(X_test.columns[i])\n        print(X_test.columns[i], ': %0d, Score: %.5f' % (i,v))\nprint(len(feats))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:44:16.906274Z","iopub.execute_input":"2022-01-25T11:44:16.906493Z","iopub.status.idle":"2022-01-25T11:44:16.916487Z","shell.execute_reply.started":"2022-01-25T11:44:16.906466Z","shell.execute_reply":"2022-01-25T11:44:16.915269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:44:16.917805Z","iopub.execute_input":"2022-01-25T11:44:16.918053Z","iopub.status.idle":"2022-01-25T11:44:16.928342Z","shell.execute_reply.started":"2022-01-25T11:44:16.918025Z","shell.execute_reply":"2022-01-25T11:44:16.927598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_X_df = X_test[feats]\nreduced_y_df = y_test","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:44:16.929238Z","iopub.execute_input":"2022-01-25T11:44:16.92956Z","iopub.status.idle":"2022-01-25T11:44:16.940241Z","shell.execute_reply.started":"2022-01-25T11:44:16.92951Z","shell.execute_reply":"2022-01-25T11:44:16.939267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_X_df","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:44:16.941348Z","iopub.execute_input":"2022-01-25T11:44:16.941616Z","iopub.status.idle":"2022-01-25T11:44:16.97692Z","shell.execute_reply.started":"2022-01-25T11:44:16.941583Z","shell.execute_reply":"2022-01-25T11:44:16.975989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_X_train = X_train[feats]\nreduced_y_train = y_train","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:44:16.978055Z","iopub.execute_input":"2022-01-25T11:44:16.978293Z","iopub.status.idle":"2022-01-25T11:44:16.984217Z","shell.execute_reply.started":"2022-01-25T11:44:16.978266Z","shell.execute_reply":"2022-01-25T11:44:16.98318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn.fit(reduced_X_train, reduced_y_train)\n\nprint('R-squared value:', knn.score(reduced_X_df,reduced_y_df))","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:44:16.985579Z","iopub.execute_input":"2022-01-25T11:44:16.985829Z","iopub.status.idle":"2022-01-25T11:44:17.821869Z","shell.execute_reply.started":"2022-01-25T11:44:16.985801Z","shell.execute_reply":"2022-01-25T11:44:17.820978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Initial model:\\n\\n', \n      model_acc, \n      '\\n\\n', 'Best Possible score for MSE is 0\\n', \n      mse_acc, \n      '\\n\\n', \n      'Best Possible score for R-Squared is 1\\n', \n      r_squared, \"\\n\\n\\n\")\n\ny_pred_reduced = knn.predict(reduced_X_df)\n\nmeasure = le.fit_transform(y_pred_reduced)\nmeasure_test = le.fit_transform(reduced_y_df)\n\nmse = mean_squared_error(measure_test, measure)\n\nprint('Reduced model:\\n\\n',\n      'Model accuracy: {0:0.4f}\\n\\n'. format(accuracy_score(reduced_y_df, y_pred)),\n      'Best Possible score for MSE is 0\\n',\n      'MSE accuracy: {0:0.4f}\\n\\n'. format(mse),\n      'Best Possible score for R-Squared is 1\\n',\n      'R-squared value:', knn.score(reduced_X_df,reduced_y_df)\n     )","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:44:17.822938Z","iopub.execute_input":"2022-01-25T11:44:17.823179Z","iopub.status.idle":"2022-01-25T11:44:19.388446Z","shell.execute_reply.started":"2022-01-25T11:44:17.823151Z","shell.execute_reply":"2022-01-25T11:44:19.387342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classification metrics\n\ninitial_model_report\n\nreduced_model_report = classification_report(reduced_y_df, y_pred_reduced)\n\nprint(\"Initial model report:\\n\", initial_model_report, \"\\n\\n\\n\", \"Reduced model report:\\n\", reduced_model_report)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:44:19.389904Z","iopub.execute_input":"2022-01-25T11:44:19.390166Z","iopub.status.idle":"2022-01-25T11:44:19.498681Z","shell.execute_reply.started":"2022-01-25T11:44:19.390127Z","shell.execute_reply":"2022-01-25T11:44:19.497925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_reduced = knn.predict(reduced_X_df)\ny_pred_reduced = pd.DataFrame({'Churn': y_pred_reduced})\ny_pred_reduced.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T11:44:19.500216Z","iopub.execute_input":"2022-01-25T11:44:19.500444Z","iopub.status.idle":"2022-01-25T11:44:20.283144Z","shell.execute_reply.started":"2022-01-25T11:44:19.500415Z","shell.execute_reply":"2022-01-25T11:44:20.282185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### E2.  Results and implications\n    * In the results from the analysis we found in a sample size of 2000 that 497 customers are predicted to churn. \n    * We oddly found that the contacts variable had the highest importance of all the features. \n    * The implication that we ran into is that the model actually ran better with more features than less. The made an initial model and found the most important features, then removed the unimportant features and the model was less accurate and had a worst MSE.\n    * The most important features were:\n     'Area',\n     'Age',\n     'Gender',\n     'Outage_sec_perweek',\n     'Email',\n     'Contacts',\n     'Yearly_equip_failure',\n     'Contract',\n     'Port_modem',\n     'Tablet',\n     'PaperlessBilling',\n     'PaymentMethod',\n     'MonthlyCharge',\n     'TimelyResponse',\n     'RespectfulResponse'\n    \n### E3.  Discuss one limitation of your data analysis.\n    * This technique could be really time consuming because of all the different variables (not features) of the model that could be configured. K can be altered, which can requires for the model to be ran every time and the feature finding algo required quite a bit of computational power. \n\n### E4.  Recommendation\n    * Based off of the information gained from the analysis, the top 3 features to the customers are the amount of contacts the customer has, if they customer has a port modem, and the kind of payment method the customer has; meaning that the company needs to focus on these features to keep the customers from churning. The accuracy of the model was not incredibly accurate, so I would recommend additional analysis with other techniques.\n    \n \n\n## Part VI: Demonstration\n\nF.  Panopto video:\n https://wgu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=163ba291-0efe-4e87-9d4b-ae240168826b\n\nG.  Third party code:\n\nSciKit-Learn (2022). sklearn.neighbors.KNeighborsClassifier. Scikit Learn. https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n\nH.  References:\nBhandari, A. (2020). AUC-ROC Curve in Machine Learning Clearly Explained. Analytics Vidhya https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n\nThirumuruganathan, S. (2010). A Detailed Introduction to K-Nearest Neighbor (KNN) Algorithm. Wordpress. https://saravananthirumuruganathan.wordpress.com/2010/05/17/a-detailed-introduction-to-k-nearest-neighbor-knn-algorithm/","metadata":{}}]}