{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multiple Regression Prediction Model\n# Data set: Telecom company churn data\n# Sean Pharris\n# January 07, 2022","metadata":{}},{"cell_type":"markdown","source":"## Part I:\n\n### A1.  Research question: Based on the 10,000 observations, how much data will be used by the customer base in the next year?\n\n### A2.  The goal of this research question will help the stakeholders percieve the sufficiency of their current tech (i.e. data bases, servers, etc.). After recieving the results, decisions for future spending on tech solutions can be made to determine the threshold of customer need.\n\n\n\n## Part II:\n\n### B1.  Multiple regression model assumptions include:\n    \n    1. Linear relationship: There exists a linear relationship between each predictor variable and the response variable (Zach, 2021).\n\n    2. No Multicollinearity: None of the predictor variables are highly correlated with each other (Zach, 2021).\n\n    3. Independence: The observations are independent (Zach, 2021).\n\n    4. Homoscedasticity: The residuals have constant variance at every point in the linear model (Zach, 2021).\n\n    5. Multivariate Normality: The residuals of the model are normally distributed (Zach, 2021).\n    \n\n\n### B2.  The benefits of Python are vast but the main reason are the versatility, ease of use, and strong support from the community. There are many packages that make it easy to undertake the task of doing data analysis/data prediction. \n\n    Some of those packages are:\n        - Pandas and Numpy - make it easy to handle large sets of data\n        - Seaborn and Matplotlib - make data visualization a breeze\n        - Statsmodels and ScikitLearn - allow for easy data exploration and prediction\n\n\n### B3.  Multiple regression is an appropriate technique to analyze the research question because our target variable, predicting how much data will be used by the customer base in the next year, is a continuous variable. There are several explanatory variables that will help us understand when trying to predict how much data a customer will use in the coming year. When adding or removing independent variables from our regression analysis, we will find out whether or not they have a positive or negative relationship to the target variable and how that might affect the company decisions on future tech solutions. \n\n\n\n## Part III:\n\n### C1.  The steps to prepare the data/manipulate the data to achieve the necessary goals are:\n            -Limiting the amount of columns to only the necessary columns\n            -Changing the categorical columns to numerical for the multiple regression model\n            -Changing any column names to make understanding easier\n            -Ensure we have no null values\n         After this is completed, the data will be prepared for analysis\n### C2.  \n    Our predictor variables will go under analysis to limit them to only the necessary variables. Finding those variables will help us determine the future data usage (our research question) and ensure us that it will be an accurate model. As defined in the data dictionary, \"The average amount of data used, in GB, in a year by the customer (if the customer is newer than a year, this value is approximated based on initia l use or of average usage for a typical customer in their demographic profile)\", meaning the average users data usage of a customers demeographic profile was used to relplace the null value of a customer that has not been at the company for a year. Customers that have not been at the company for a year will not be entirely accurate. We do know that the average for the entire customer base is 3392.3415497352817.\n    \n    Predictor variables: \n        'Children', 'Age', 'Income', 'Churn', 'Outage_sec_perweek', 'Yearly_equip_failure', 'Techie', 'Port_modem', 'Tablet','InternetService', 'Phone', 'Multiple',\n        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Tenure',\n        'MonthlyCharge','TimelyResponse', 'TimelyFixes', 'TimelyReplacements', 'Reliability', 'Options', 'RespectfulResponse', 'CourteousExchange',\n        'EvidenceOfActiveListening'\n    Target: \n        'Bandwidth_GB_Year'\n\n\n### C3.  The steps to prepare the data are:\n     1. Read the data into the data frame (\"df\") using Pandas \"read_csv()\"\n     2. Drop unneeded columns\n     3. Create dummy variables in order to analyze yes/no columns\n     4. Make sure all values are numerical\n     5. Make sure there are no null values\n     \n     The code is below","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-11T13:07:43.953267Z","iopub.execute_input":"2022-01-11T13:07:43.953565Z","iopub.status.idle":"2022-01-11T13:07:43.964202Z","shell.execute_reply.started":"2022-01-11T13:07:43.953533Z","shell.execute_reply":"2022-01-11T13:07:43.963601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read in data set into the data frame \ndf = pd.read_csv('../input/clean-churn-data/churn_clean.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:43.96568Z","iopub.execute_input":"2022-01-11T13:07:43.966016Z","iopub.status.idle":"2022-01-11T13:07:44.086607Z","shell.execute_reply.started":"2022-01-11T13:07:43.965988Z","shell.execute_reply":"2022-01-11T13:07:44.085819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View the data set\ndf.head","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.088097Z","iopub.execute_input":"2022-01-11T13:07:44.088615Z","iopub.status.idle":"2022-01-11T13:07:44.110605Z","shell.execute_reply.started":"2022-01-11T13:07:44.088572Z","shell.execute_reply":"2022-01-11T13:07:44.109613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Bandwidth_GB_Year'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.112943Z","iopub.execute_input":"2022-01-11T13:07:44.113267Z","iopub.status.idle":"2022-01-11T13:07:44.119073Z","shell.execute_reply.started":"2022-01-11T13:07:44.113225Z","shell.execute_reply":"2022-01-11T13:07:44.118274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the column names\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.120526Z","iopub.execute_input":"2022-01-11T13:07:44.121013Z","iopub.status.idle":"2022-01-11T13:07:44.131689Z","shell.execute_reply.started":"2022-01-11T13:07:44.120973Z","shell.execute_reply":"2022-01-11T13:07:44.131016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop unneeded columns\ndf.drop(columns=['CaseOrder', 'Customer_id', 'Interaction', 'UID', 'City', 'State',\n       'County', 'Zip', 'Lat', 'Lng', 'Population', 'Area', 'TimeZone', 'Job', \n                 'Marital', 'Gender', 'Email', 'Contacts', 'Contract', 'PaymentMethod'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.132577Z","iopub.execute_input":"2022-01-11T13:07:44.133083Z","iopub.status.idle":"2022-01-11T13:07:44.148286Z","shell.execute_reply.started":"2022-01-11T13:07:44.133055Z","shell.execute_reply":"2022-01-11T13:07:44.147451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating dummy variables for yes/no columns and the InternetService column.\nfor col in df:\n    df[col].replace(('Yes', 'No'), (1, 0), inplace=True)\n    \ndf['InternetService'].replace(('Fiber Optic', 'DSL', 'None'), (1, 0, 0), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.149486Z","iopub.execute_input":"2022-01-11T13:07:44.149696Z","iopub.status.idle":"2022-01-11T13:07:44.268312Z","shell.execute_reply.started":"2022-01-11T13:07:44.149671Z","shell.execute_reply":"2022-01-11T13:07:44.267558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensuring that all columns are numerical\nfor col in df:\n    print(df[col].unique())","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.269443Z","iopub.execute_input":"2022-01-11T13:07:44.269653Z","iopub.status.idle":"2022-01-11T13:07:44.297579Z","shell.execute_reply.started":"2022-01-11T13:07:44.269628Z","shell.execute_reply":"2022-01-11T13:07:44.296578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.301063Z","iopub.execute_input":"2022-01-11T13:07:44.301397Z","iopub.status.idle":"2022-01-11T13:07:44.392941Z","shell.execute_reply.started":"2022-01-11T13:07:44.301364Z","shell.execute_reply":"2022-01-11T13:07:44.392101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the null values for each column\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.394004Z","iopub.execute_input":"2022-01-11T13:07:44.394227Z","iopub.status.idle":"2022-01-11T13:07:44.40381Z","shell.execute_reply.started":"2022-01-11T13:07:44.394201Z","shell.execute_reply":"2022-01-11T13:07:44.402967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Renaming the survey columns\ndf.rename(columns = {'Item1':'TimelyResponse', \n                    'Item2':'TimelyFixes', \n                     'Item3':'TimelyReplacements', \n                     'Item4':'Reliability', \n                     'Item5':'Options', \n                     'Item6':'RespectfulResponse', \n                     'Item7':'CourteousExchange', \n                     'Item8':'EvidenceOfActiveListening'}, \n          inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.405068Z","iopub.execute_input":"2022-01-11T13:07:44.405387Z","iopub.status.idle":"2022-01-11T13:07:44.412511Z","shell.execute_reply.started":"2022-01-11T13:07:44.405358Z","shell.execute_reply":"2022-01-11T13:07:44.411872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.413634Z","iopub.execute_input":"2022-01-11T13:07:44.413849Z","iopub.status.idle":"2022-01-11T13:07:44.430567Z","shell.execute_reply.started":"2022-01-11T13:07:44.413824Z","shell.execute_reply":"2022-01-11T13:07:44.429858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### C4.  Generate univariate and bivariate visualizations of the distributions of variables in the cleaned data set. Include the target variable in your bivariate visualizations.","metadata":{}},{"cell_type":"code","source":"# Univariate visualizations of the independent variables\n\nfrom matplotlib import pyplot as plt\nfor col in df:\n    if len(df[col].unique()) > 3:\n        df[[col]].hist()\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:44.431627Z","iopub.execute_input":"2022-01-11T13:07:44.431958Z","iopub.status.idle":"2022-01-11T13:07:47.694325Z","shell.execute_reply.started":"2022-01-11T13:07:44.431931Z","shell.execute_reply":"2022-01-11T13:07:47.693638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfor col in df:\n    if len(df[col].unique()) > 3:\n        sns.boxplot(x = col, data = df)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:47.695529Z","iopub.execute_input":"2022-01-11T13:07:47.69586Z","iopub.status.idle":"2022-01-11T13:07:49.577936Z","shell.execute_reply.started":"2022-01-11T13:07:47.695831Z","shell.execute_reply":"2022-01-11T13:07:49.577065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bivariate visualizations of the independent variables\n\nimport seaborn as sns\nfor col in df:\n    if col != 'Bandwidth_GB_Year' and len(df[col].unique()) > 3:\n        sns.scatterplot(x=df[col], y=df['Bandwidth_GB_Year'])\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:49.579629Z","iopub.execute_input":"2022-01-11T13:07:49.579944Z","iopub.status.idle":"2022-01-11T13:07:52.505645Z","shell.execute_reply.started":"2022-01-11T13:07:49.579901Z","shell.execute_reply":"2022-01-11T13:07:52.504714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### C5. ","metadata":{}},{"cell_type":"code","source":"# Desired data set\ndf.to_csv('multiple_regression_churn.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:07:52.506958Z","iopub.execute_input":"2022-01-11T13:07:52.507174Z","iopub.status.idle":"2022-01-11T13:07:52.639472Z","shell.execute_reply.started":"2022-01-11T13:07:52.507147Z","shell.execute_reply":"2022-01-11T13:07:52.638581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Part IV:\n\n### D1.  Construct an initial multiple regression model from all predictors that were identified in Part C2.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as api\n\ndf['Intercept'] = 1\ninitial_model = api.OLS(df['Bandwidth_GB_Year'], df[['Children', 'Age', 'Income', 'Churn', 'Outage_sec_perweek',\n                                                               'Yearly_equip_failure', 'Techie', 'Port_modem', 'Tablet',\n                                                               'InternetService', 'Phone', 'Multiple', 'OnlineSecurity',\n                                                               'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n                                                               'StreamingMovies', 'PaperlessBilling', 'Tenure', 'MonthlyCharge','TimelyResponse', 'TimelyFixes',\n                                                               'TimelyReplacements', 'Reliability', 'Options', 'RespectfulResponse',\n                                                               'CourteousExchange', 'EvidenceOfActiveListening', 'Intercept']]).fit()\nprint(initial_model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:44:14.916548Z","iopub.execute_input":"2022-01-11T13:44:14.916963Z","iopub.status.idle":"2022-01-11T13:44:14.987841Z","shell.execute_reply.started":"2022-01-11T13:44:14.916931Z","shell.execute_reply":"2022-01-11T13:44:14.984241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### D2.  Reducing the model\n- Using the above OLS Regression results, we will only use variables with p-values of 0 because the closer the number is to 0 the more statistically significant the variable is.\n- We will also only take the variables with the highest positive coefficients becasue the numbers help determine our predictor.\n\n    Summary: We will reduce the model to only have variables with a p-value of 0 and highest positve coefficients so that our included variables will accurately and efficiently predict our dependent variable.","metadata":{}},{"cell_type":"markdown","source":"### D3.  Reduced multiple regression model that includes both categorical and continuous variables","metadata":{}},{"cell_type":"code","source":"# We can now create a reduced data frame for our reduced model \nreduced_df = df[['Children','Tenure','OnlineSecurity','Bandwidth_GB_Year', 'Intercept']]","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:45:44.682106Z","iopub.execute_input":"2022-01-11T13:45:44.683175Z","iopub.status.idle":"2022-01-11T13:45:44.689787Z","shell.execute_reply.started":"2022-01-11T13:45:44.683116Z","shell.execute_reply":"2022-01-11T13:45:44.688632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creation of the reduced model\n\nreduced_model = api.OLS(reduced_df['Bandwidth_GB_Year'], reduced_df[['Children', 'Tenure','OnlineSecurity', 'Intercept']]).fit()\n\nprint(reduced_model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:45:46.892209Z","iopub.execute_input":"2022-01-11T13:45:46.893333Z","iopub.status.idle":"2022-01-11T13:45:46.932349Z","shell.execute_reply.started":"2022-01-11T13:45:46.893269Z","shell.execute_reply":"2022-01-11T13:45:46.931226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### E1.  Initial/Reduced Model Comparison - R-squared valued = Explained variance\n- The variable selection technique conducted to come up with the reduced model consisted of:  \n        - Extraction of variables with a p-value of 0\n        - Then took the variables with the highest positive coefficients becasue the numbers help determine our predictor.\n- The initial model had an R-squared value of 1.0(100%) using 29 variables. After reducing the model to 3 independent vairables, we had an R-squared value of 0.984(98.4%).\n- We can now continue to answer the research question with a much smaller model to be more resourceful.","metadata":{}},{"cell_type":"code","source":"# Residual plot \nresidual_plot = df['Bandwidth_GB_Year'] - reduced_model.predict(df[['Children', 'Tenure','OnlineSecurity', 'Intercept']])\nsns.residplot(x=df['Bandwidth_GB_Year'],y=residual_plot)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:49:52.277872Z","iopub.execute_input":"2022-01-11T13:49:52.278847Z","iopub.status.idle":"2022-01-11T13:49:52.56068Z","shell.execute_reply.started":"2022-01-11T13:49:52.27879Z","shell.execute_reply":"2022-01-11T13:49:52.559862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction plot\nprediction_plot = reduced_model.predict(df[['Children', 'Tenure','OnlineSecurity', 'Intercept']])\nsns.scatterplot(x=df['Bandwidth_GB_Year'],y=prediction_plot)\nplt.show()\nprint(prediction_plot)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:50:03.456942Z","iopub.execute_input":"2022-01-11T13:50:03.457305Z","iopub.status.idle":"2022-01-11T13:50:03.718696Z","shell.execute_reply.started":"2022-01-11T13:50:03.457269Z","shell.execute_reply":"2022-01-11T13:50:03.718076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The data usage total of the last year\ndf['Bandwidth_GB_Year'].sum()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T13:50:13.196823Z","iopub.execute_input":"2022-01-11T13:50:13.197112Z","iopub.status.idle":"2022-01-11T13:50:13.204954Z","shell.execute_reply.started":"2022-01-11T13:50:13.197083Z","shell.execute_reply":"2022-01-11T13:50:13.203879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### E2/E3.  All code and outputs are above.\n\n\n\n## Part V: \n\n### F1.  Discuss the results of your data analysis, including the following elements:\n\n- Regression equation:  \n    Gigabytes of Bandwidth per Year = 497.77 + 31.16(Children) + 81.95(Tenure) + 83.47(OnlineSecurity)\n\n- Statistically significant independent variables:\n    - Children (coef = 31.16)\n    - Tenure (coef = 81.95)\n    - OnlineSecurity (coef = 83.47)\n- Statistically significant dependent variables:\n    - Gigabytes of Bandwidth per Year\n- Interpretation:\n    Every time an independent variable increases by 1 the GBs of Bandwidth Per Year increases by their coefficient\n    \n    Example:\n        The customer has 2 children and has been a company for 2 years.\n        Children = 2\n        Tenure = 2\n        OnlineSecurity = No (The customer does not have OnlineSecurity so this equals to 0)\n        \n        GBs of Bandwidth Per Year = 497.77 + 31.16(2) + 81.95(2) + 83.47(0)\n        GBs of Bandwidth Per Year = 497.77 + 62.32 + 163.9 + 0\n        \n        Result:\n        GBs of Bandwidth Per Year = 723.99\n        \n- Significance:\n    - We can see that the amount of kids the customer has and how the customer has been with the Telecom company are our major factors of the model. The Tenure of the customer has the largest role in how much data the customer will use.\n\n- Limitations:\n    - If we had the historical data of the customers for several years we could provide a more accurate model to predict the coming years data usage. \n\n### F2.  Recommend a course of action based on your results.\n- The past years data usage total was 33923415.5 and based on what we now know, we can assume this number will grow. We do not know what the plans for the telecom company but we can suggest an upgrade in their tech solutions moving forward. If we had historical data we could make an accurate suggestion to how much it might grow. We do know that roughly 3000 customers have left the company in the past month and we do not know the company growth rate, so we can not account for those customers.  \n\n\n## Part VI:\n\n### G.  Panopto video recording:\n\nhttps://wgu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=5eaf6850-9717-43f3-b56f-ae14016e90c0\n\n\n\n### H.  Sources for Third Party Code:\n\nMatplotlib documentation (2021) Matplotlib documentation. Matplotlib. https://matplotlib.org/stable/index.html\n\nWaskom, M (2021) Seaborn: Statistical data visualization. Seaborn. https://seaborn.pydata.org/index.html\n\n### I.  References:\n\nZach. (2021). The five assumptions of multiple linear regression. Statology. https://www.statology.org/multiple-linear-regression-assumptions/ ","metadata":{}}]}